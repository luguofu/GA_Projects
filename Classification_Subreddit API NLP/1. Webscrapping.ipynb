{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87836a0f",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: centre; margin: 20px; height: 55px\"> \n",
    "\n",
    "# Project 3: Web API & NLP Part 1: Webscrapping, API"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78d7fa3f",
   "metadata": {},
   "source": [
    "## Problem Statement\n",
    "\n",
    "We are tasked to utilize and train a classifier on a binary classification problem to predict which subreddit a given post comes from either Phuket or Bali island (our selected choice). Gathering of our data will be through web scrapping data from reddit using API.\n",
    "\n",
    "Our solution is 2 fold:\n",
    "- Using Pushshift's API to scrap for bali and phuket posts.\n",
    "- Use NLP to train a classifier, 1)RandomforrestClassifier and 2)logistic regression model on which subreddit a given post came from."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "680b134f",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f14750",
   "metadata": {},
   "source": [
    "This project is a binary classification problem which aims to utilize NLP to train a classifier of scrapped data from subreddit using API to classify which reddit post it came from. \n",
    "\n",
    "We have selected the topics which will be places of tourist beach interests, Bali and Phuket. These 2 places are familier to holiday beach-goers from the south east asian region and are similar in type of tourist activites in nature. Given the current pandemic situation, both islands faced limited visitors from foreign countries. It will be interesting to see what are the results we yield from the analysis of this project.\n",
    "\n",
    "Utilizing the API, we scarpped 8 loops of posts and 4 types of datasets, namely the submission and comments posts from each classification. we then cleaned and merged the data together as a single set. we've concat the comment post to the submission posts as we will like to know what are the words that are used in the different classification topic.\n",
    "\n",
    "For the modelling, we choose the Logistic Regression and RandomForestClassifier for our modelling. utilizing pipelines to conduct feature engineering and using gridsearchcv to get the best parameters for our models.\n",
    "\n",
    "Resulting with Logistic Regression model with the better consistent scoring model.Therefore we reccomend the LogisticRegression model for our binary classifier\n",
    "\n",
    "\n",
    "*The following are a brief description of the islands for our commonn understanding of the individual island description. These information will come in handy during our analysis.\n",
    "\n",
    "1. Bali: an Indonesian island known for its forested volcanic mountains, iconic rice paddies, beaches and coral reefs. The island is home to religious sites such as cliffside Uluwatu Temple. To the south, the beachside city of Kuta has lively bars, while Seminyak, Sanur and Nusa Dua are popular resort towns. The island is also known for its yoga and meditation retreats.\n",
    "ref: https://en.wikipedia.org/wiki/Bali\n",
    "\n",
    "2. Phuket: A Thai province located in south of Thailand. It is the biggest Island of Thailand and sits on the Andaman sea. The nearest province to the north is Phang-nga and the nearest provinces to the east are Phang-nga and Krabi. Phuket has a large Chinese influence, therefore you will find many Chinese shrines and Chinese Restaurants around the city.Being a big island, Phuket is surrounded by many magnificent Beaches such as Rawai, Patong, Karon, Kamala, Kata Yai, Kata Noi, and Mai Khao. Laem Phromthep viewpoint is said to feature the most beautiful sunsets in Thailand. It isnâ€™t all just beaches though, there is also the famous Phuket NIGHTLIFE,and is a hotspot for tourists in Thailand.\n",
    "ref: https://www.tourismthailand.org/Destinations/Provinces/Phuket/350\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e36fd8",
   "metadata": {},
   "source": [
    "## Contents:\n",
    "\n",
    "### Part 1:\n",
    "- Import Library\n",
    "- Data Collection: Web Scrapping using API\n",
    "- Data Dictionary\n",
    "\n",
    "\n",
    "### Part 2:\n",
    "- Data Cleaning\n",
    "- Import Library and Datasets\n",
    "- Preprocessing\n",
    "- EDA\n",
    "- Modelling\n",
    "- Evaluation\n",
    "- Conclusion & Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c5d64c",
   "metadata": {},
   "source": [
    "### Import Library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "14d31c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import re\n",
    "import time\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56afceec",
   "metadata": {},
   "source": [
    "- Problem Statement\n",
    "- Data Collection\n",
    "- Data Cleaning & EDA\n",
    "- Preprocessing & Modeling\n",
    "- Evaluation and Conceptual Understanding\n",
    "- Conclusion and Recommendations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02745bd5",
   "metadata": {},
   "source": [
    "## Data Collection: Web Scrapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95d17ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create function for web scrapping submissions:\n",
    "\n",
    "def scrapping(url, loops, subreddit):\n",
    "    df = []\n",
    "    start_time = time.time() # get the time in seconds since epoch\n",
    "    params = {'subreddit': subreddit,\n",
    "    'size': 100,\n",
    "    'before': round(start_time)\n",
    "    }\n",
    "    \n",
    "    for i in range(loops):\n",
    "        current_time = time.time()\n",
    "        #requesting data\n",
    "        res = requests.get(url, params)\n",
    "        print(f'res status {i+1}: ', res.status_code)\n",
    "        \n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        post_df = pd.DataFrame(posts)\n",
    "        df.append(post_df)\n",
    "        #get oldest post time and use as before parameter in next request\n",
    "        old = post_df['created_utc'].min()\n",
    "        params['before'] = old\n",
    "        time.sleep(1)\n",
    "        reddit_posts = pd.concat(df)\n",
    "\n",
    "        filename = subreddit + '_submission.csv'\n",
    "\n",
    "    return reddit_posts.to_csv('./datasets/' + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "dc246472",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res status 1:  200\n",
      "res status 2:  200\n",
      "res status 3:  200\n",
      "res status 4:  200\n",
      "res status 5:  200\n",
      "res status 6:  200\n",
      "res status 7:  200\n",
      "res status 8:  200\n"
     ]
    }
   ],
   "source": [
    "# scrape for bali submission data set from Reddit.\n",
    "url = 'https://api.pushshift.io/reddit/submission/search'\n",
    "loops = 8 # no. of loops to scrap\n",
    "subreddit = 'bali' # subreddit topic\n",
    "\n",
    "scrapping(url, loops, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aaff8ddc",
   "metadata": {},
   "outputs": [],
   "source": [
    "bali_submission = pd.read_csv('./datasets/bali_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8194881d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 84)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bali_submission.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "432bad55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bali</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PARASHAKTI AKASHIC READING || 22 SEPT 2021</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bali</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>SBOBET PUSAT JUDI ONLINE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bali</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>North Bali beachfront resort offered for sale ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bali</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Coming to Bali from Australia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bali</td>\n",
       "      <td>[removed]</td>\n",
       "      <td>Getting into bali with a business visa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit   selftext                                              title\n",
       "0      bali        NaN         PARASHAKTI AKASHIC READING || 22 SEPT 2021\n",
       "1      bali  [removed]                           SBOBET PUSAT JUDI ONLINE\n",
       "2      bali  [removed]  North Bali beachfront resort offered for sale ...\n",
       "3      bali  [removed]                      Coming to Bali from Australia\n",
       "4      bali  [removed]             Getting into bali with a business visa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract out the necessary features of the df\n",
    "bali_df = bali_submission[['subreddit', 'selftext', 'title']]\n",
    "bali_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "8c8bb285",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res status 1:  200\n",
      "res status 2:  200\n",
      "res status 3:  200\n",
      "res status 4:  200\n",
      "res status 5:  200\n",
      "res status 6:  200\n",
      "res status 7:  200\n",
      "res status 8:  200\n"
     ]
    }
   ],
   "source": [
    "# scrape for phuket submission data set from Reddit.\n",
    "url = 'https://api.pushshift.io/reddit/submission/search'\n",
    "loops = 8 # no. of loops to scrap\n",
    "subreddit = 'phuket' # subreddit topic\n",
    "\n",
    "scrapping(url, loops, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3ce981d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phuket_submi = pd.read_csv('./datasets/phuket_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2cda77e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>selftext</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Just curious if anyone knows the rules, hard f...</td>\n",
       "      <td>Travel from Phuket to Bangkok after 14 day san...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Hi, just wondering if anyone wanted to grab so...</td>\n",
       "      <td>Drinks Saturday in Patong?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phuket</td>\n",
       "      <td>With current restrictions, do you think Phuket...</td>\n",
       "      <td>Is Phuket good destination for honeymoon?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Hi, is an unvaccinated Thai national still abl...</td>\n",
       "      <td>Unvaccinated domestic travel.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phuket</td>\n",
       "      <td>We've visited the 5 major beach towns on the w...</td>\n",
       "      <td>Review of Phuket's beach towns since beginning...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                           selftext  \\\n",
       "0    phuket  Just curious if anyone knows the rules, hard f...   \n",
       "1    phuket  Hi, just wondering if anyone wanted to grab so...   \n",
       "2    phuket  With current restrictions, do you think Phuket...   \n",
       "3    phuket  Hi, is an unvaccinated Thai national still abl...   \n",
       "4    phuket  We've visited the 5 major beach towns on the w...   \n",
       "\n",
       "                                               title  \n",
       "0  Travel from Phuket to Bangkok after 14 day san...  \n",
       "1                         Drinks Saturday in Patong?  \n",
       "2          Is Phuket good destination for honeymoon?  \n",
       "3                      Unvaccinated domestic travel.  \n",
       "4  Review of Phuket's beach towns since beginning...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# extract out the necessary features of the df\n",
    "phuket_df = phuket_submi[['subreddit', 'selftext', 'title']]\n",
    "phuket_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e85ed479",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 3)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phuket_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "21e455bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creat function for web scrapping comments:\n",
    "\n",
    "def scrapping(url, loops, subreddit):\n",
    "    df = []\n",
    "    start_time = time.time() # get the time in seconds since epoch\n",
    "    params = {'subreddit': subreddit,\n",
    "    'size': 100,\n",
    "    'before': round(start_time)\n",
    "    }\n",
    "    \n",
    "    for i in range(loops):\n",
    "        current_time = time.time()\n",
    "        #requesting data\n",
    "        res = requests.get(url, params)\n",
    "        print(f'res status {i+1}: ', res.status_code)\n",
    "        \n",
    "        data = res.json()\n",
    "        posts = data['data']\n",
    "        post_df = pd.DataFrame(posts)\n",
    "        df.append(post_df)\n",
    "        #get oldest post time and use as before parameter in next request\n",
    "        old = post_df['created_utc'].min()\n",
    "        params['before'] = old\n",
    "        time.sleep(1)\n",
    "        reddit_posts = pd.concat(df)\n",
    "\n",
    "        filename = subreddit + '_comment.csv'\n",
    "\n",
    "    return reddit_posts.to_csv('./datasets/' + filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc750932",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res status 1:  200\n",
      "res status 2:  200\n",
      "res status 3:  200\n",
      "res status 4:  200\n",
      "res status 5:  200\n",
      "res status 6:  200\n",
      "res status 7:  200\n",
      "res status 8:  200\n"
     ]
    }
   ],
   "source": [
    "# scrape for bali comments data set from Reddit.\n",
    "url = 'https://api.pushshift.io/reddit/comment/search'\n",
    "loops = 8 # no. of loops to scrap\n",
    "subreddit = 'bali' # subreddit topic\n",
    "\n",
    "scrapping(url, loops, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "36c57ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "bali_comm = pd.read_csv('./datasets/bali_comment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "fad29605",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  800 non-null    object\n",
      " 1   body       800 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# extract out the necessary features of the df\n",
    "bali_comments = bali_comm[['subreddit', 'body']]\n",
    "bali_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "60388d6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bali</td>\n",
       "      <td>I have no idea about the official visa website...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bali</td>\n",
       "      <td>Your submission has been removed for suspected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bali</td>\n",
       "      <td>You need a specialised Covid19 test for overse...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bali</td>\n",
       "      <td>Your submission has been removed for suspected...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>bali</td>\n",
       "      <td>It's entirely possible I posted this in anothe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                               body\n",
       "0      bali  I have no idea about the official visa website...\n",
       "1      bali  Your submission has been removed for suspected...\n",
       "2      bali  You need a specialised Covid19 test for overse...\n",
       "3      bali  Your submission has been removed for suspected...\n",
       "4      bali  It's entirely possible I posted this in anothe..."
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check \n",
    "bali_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3a31bb37",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res status 1:  200\n",
      "res status 2:  200\n",
      "res status 3:  200\n",
      "res status 4:  200\n",
      "res status 5:  200\n",
      "res status 6:  200\n",
      "res status 7:  200\n",
      "res status 8:  200\n"
     ]
    }
   ],
   "source": [
    "# scrape for phuket comments data set from Reddit.\n",
    "url = 'https://api.pushshift.io/reddit/comment/search'\n",
    "loops = 8 # no. of loops to scrap\n",
    "subreddit = 'phuket' # subreddit topic\n",
    "\n",
    "scrapping(url, loops, subreddit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ca872e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "phuket_comm = pd.read_csv('./datasets/phuket_comment.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "709a822a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 800 entries, 0 to 799\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   subreddit  800 non-null    object\n",
      " 1   body       800 non-null    object\n",
      "dtypes: object(2)\n",
      "memory usage: 12.6+ KB\n"
     ]
    }
   ],
   "source": [
    "# extract out the necessary features of the df\n",
    "phuket_comments = phuket_comm[['subreddit', 'body']]\n",
    "phuket_comments.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "46c351b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>phuket</td>\n",
       "      <td>You'll need an ART test I believe available at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Perfect.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Yesyes, sound good. \\nIf im still iâ€™ll DM you,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Anything I'm easy going just some drinks to st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>phuket</td>\n",
       "      <td>Thank you very much!</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  subreddit                                               body\n",
       "0    phuket  You'll need an ART test I believe available at...\n",
       "1    phuket                                           Perfect.\n",
       "2    phuket  Yesyes, sound good. \\nIf im still iâ€™ll DM you,...\n",
       "3    phuket  Anything I'm easy going just some drinks to st...\n",
       "4    phuket                               Thank you very much!"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#check\n",
    "phuket_comments.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fa54af91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(800, 2)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phuket_comments.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4797e272",
   "metadata": {},
   "source": [
    "- We have now scrapped 4 sets of data. each set contains 800 rows\n",
    "1. Bali submission\n",
    "2. Bali comments\n",
    "3. Phuket submission\n",
    "4. Phuket commnets"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbbedf53",
   "metadata": {},
   "source": [
    "### Data Dictionary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9142368",
   "metadata": {},
   "source": [
    "| S/N | Data | Description | File |\n",
    "|:---:|:---:|:---:|:---:|\n",
    "| 1 | phuket_df | scrapped submission posts of phuket from reddit | phuket_submission.csv |\n",
    "| 2 | phuket_comments | scrapped comments posts of phuket from reddit | phuket_comments.csv |\n",
    "| 3 | bali_df | scrapped submission posts of bali from reddit | bali_submission.csv |\n",
    "| 4 | bali_comments | scrapped submission posts of bali from reddit | phuket_comments.csv |\n",
    "| 5 | df | combined cleaned dataset | df_clean.csv |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
